# Summary
Various problems arise when Machine learning algorithms are trained with the standard **utility-maximization objectives**
- decisions which human observer might consider unfair (e.g. biased towards a minority) - **machine bias**
    - the field of **algorithmic faires:** tries to solve this - algorithms can have life altering consequences (mortgage terms, medical care, ...)
        - e.g. word-2-vec contains implicit gender bias 

## Research:
- [Bias in Bios: A Case Study of Semantic Representation Bias in a
High-Stakes Setting
](https://arxiv.org/pdf/1901.09451.pdf)

# Read more:
- fairness: https://towardsdatascience.com/a-gentle-introduction-to-the-discussion-on-algorithmic-fairness-740bbb469b6